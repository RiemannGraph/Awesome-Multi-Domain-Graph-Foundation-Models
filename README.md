# Awesome-Multi-Domain-Graph-Foundation-Models
Paper List about multi-domain graph foundation models

## Multi-domain Pretraining GFMs

- **(WWW 2025)** **SAMGPT: Text-free Graph Foundation Model for Multi-domain Pre-training and Cross-domain Adaptation**  
  [Paper](https://arxiv.org/abs/2502.05424) | [Code](https://github.com/blue-soda/samgpt)

- **(WWW 2025)** **RiemannGFM: Learning a Graph Foundation Model from Riemannian Geometry**  
  [Paper](https://arxiv.org/abs/2502.03251) | [Code](https://github.com/RiemannGraph/RiemannGFM)

- **(KDD 2024)** **One for All: Towards Training One Graph Model for All Classification Tasks**  
  [Paper](https://arxiv.org/abs/2402.09834) | [Code](https://github.com/cshhzhao/GCOPE)

- **(LoG 2024)** **A Pure Transformer Pretraining Framework on Text-attributed Graphs**  
  [Paper](https://arxiv.org/abs/2406.13873) | [Code](https://github.com/SongYYYY/GSP)


## General Purpose GFMs

- **(NeurIPS 2024)** **GFT: Graph Foundation Model with Transferable Tree Vocabulary**  
  [Paper](https://arxiv.org/abs/2411.06070) | [Code](https://github.com/Zehong-Wang/GFT)

- **(ICLR 2025)** **GOFA: A Generative One-For-All Model for Joint Graph Language Modeling**  
  [Paper](https://openreview.net/pdf?id=mIjblC9hfm) | [Code](https://github.com/JiaruiFeng/GOFA)

- **(ICML 2025)** **GraphGPT: Generative Pre-trained Graph Eulerian Transformer**  
  [Paper](https://arxiv.org/abs/2401.00529) | [Code](https://github.com/alibaba/graph-gpt)

- **(NeurIPS 2025)** **Unifying and Enhancing Graph Transformers via a Hierarchical Mask Framework**  
  [Paper](https://arxiv.org/abs/2510.18825) | [Code](https://github.com/null-xyj/M3Dphormer)

- **(NeurIPS 2025)** **Deeper with Riemannian Geometry: Overcoming Oversmoothing and Oversquashing for Graph Foundation Models**  
  [Paper](https://arxiv.org/abs/2510.17457) | [Code](https://github.com/ZhenhHuang/GBN)


## Text-Attributed Graph GFMs

- **(WWW 2025)** **GraphCLIP: Enhancing Transferability in Graph Foundation Models for Text-Attributed Graphs**  
  [Paper](https://arxiv.org/abs/2410.10329) | [Code](https://github.com/ZhuYun97/GraphCLIP)

- **(NeurIPS 2025)** **SSTAG: Structure-Aware Self-Supervised Learning Method for Text-Attributed Graphs**  
  [Paper](https://arxiv.org/abs/2510.01248) | [Code](https://github.com/Liury925/SSTAG)

-  **LLM as GNN: Graph Vocabulary Learning for Text-Attributed Graph Foundation Models**  
  [Paper](https://arxiv.org/abs/2503.03313) | [Code](https://github.com/agiresearch/PromptGFM)


## Task-specific GFMs

### Anomaly Detection
- **(KDD 2025)** **AnomalyGFM: Graph Foundation Model for Zero-shot/Few-shot Anomaly Detection**  
  [Paper](https://arxiv.org/abs/2502.09254) | [Code](https://github.com/mala-lab/AnomalyGFM)

### Node Classification
- **(AAAI 2025)** **Tokenphormer: Structure-aware Multi-token Graph Transformer for Node Classification**  
  [Paper](https://arxiv.org/abs/2412.15302) 

### Knowledge Graph Reasoning
- **(NeurIPS 2024)** **A Prompt-Based Knowledge Graph Foundation Model for Universal In-Context Reasoning**  
  [Paper](https://arxiv.org/abs/2410.12288) | [Code](https://github.com/nju-websoft/KG-ICL)

### Retrieval Augmented Generation
- **(NeurIPS 2025)** **GFM-RAG: Graph Foundation Model for Retrieval Augmented Generation**  
  [Paper](https://arxiv.org/abs/2502.01113) | [Code](https://github.com/RManLuo/gfm-rag)


## Adaptive & Incremental GFMs

- **(ICML 2025)** **AutoGFM: Automated Graph Foundation Model with Adaptive Architecture Customization**  
  [Paper](https://openreview.net/pdf?id=fCPB0qRJT2) 

- **(NeurIPS 2025)** **GraphKeeper: Graph Domain-Incremental Learning via Knowledge Disentanglement and Preservation**  
  [Paper](https://arxiv.org/abs/2511.00097) | [Code](https://github.com/RingBDStack/GraphKeeper)

- **(NeurIPS 2025)** **GRAVER: Generative Graph Vocabularies for Robust Graph Foundation Models Fine-tuning**  
  [Paper](https://arxiv.org/abs/2511.05592) | [Code](https://github.com/RingBDStack/GRAVER)


## Federated Graph GFMs

- **(NeurIPS 2025)** **Towards Effective Federated Graph Foundation Model via Mitigating Knowledge Entanglement**  
  [Paper](https://arxiv.org/abs/2505.12684) 
